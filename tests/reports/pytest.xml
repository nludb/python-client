<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="5" skipped="0" tests="5" time="179.411" timestamp="2022-05-23T15:55:16.476697" hostname="Eniass-MacBook-Pro.local"><testcase classname="tests.tests.plugin.integration.test_e2e_trainable_tagger" name="test_e2e_trainable_tagger_lambda_training" time="173.476"><failure message="pydantic.error_wrappers.ValidationError: 1 validation error for ModelCheckpoint&#10;space&#10;  field required (type=value_error.missing)">def test_e2e_trainable_tagger_lambda_training():
        client = get_steamship_client()
        spaceR = Space.get(client)
        assert spaceR.data is not None
        space = spaceR.data
    
        version_config_template = dict(
            text_column=dict(type="string"),
            tag_columns=dict(type="string"),
            tag_kind=dict(type="string"),
        )
        instance_config = dict(text_column="Message", tag_columns="Category", tag_kind="Intent")
    
        exporter_plugin_r = PluginInstance.create(
            client=client,
            handle=EXPORTER_HANDLE,
            plugin_handle=EXPORTER_HANDLE,
            upsert=True,
        )
        assert exporter_plugin_r.data is not None
        exporter_plugin = exporter_plugin_r.data
        assert exporter_plugin.handle is not None
    
        csv_blockifier_path = PLUGINS_PATH / "blockifiers" / "csv_blockifier.py"
        trainable_tagger_path = PLUGINS_PATH / "taggers" / "plugin_trainable_tagger.py"
    
        # Make a blockifier which will generate our trainable corpus
        with deploy_plugin(
            client,
            csv_blockifier_path,
            "blockifier",
            version_config_template=version_config_template,
            instance_config=instance_config,
        ) as (plugin, version, instance):
            with upload_file(client, "utterances.csv") as file:
                assert len(file.refresh().data.blocks) == 0
                # Use the plugin we just registered
                file.blockify(plugin_instance=instance.handle).wait()
                assert len(file.refresh().data.blocks) == 5
    
                # Now make a trainable tagger to train on those tags
                with deploy_plugin(
                    client, trainable_tagger_path, "tagger", training_platform=HostingType.LAMBDA
                ) as (tagger, tagger_version, tagger_instance):
                    # Now train the plugin
                    training_request = TrainingParameterPluginInput(
                        plugin_instance=tagger_instance.handle,
                        export_request=ExportPluginInput(
                            plugin_instance=EXPORTER_HANDLE, type="corpus", handle="default"
                        ),
                        training_params=dict(
                            keyword_list=KEYWORDS  # This is a key defined by the test model we're training
                        ),
                    )
    
                    train_result = tagger_instance.train(training_request)
                    train_result.wait()
    
                    # At this point, the PluginInstance will have written a parameter file to disk. We should be able to
                    # retrieve it since we know that it is tagged as the `default`.
    
&gt;                   checkpoint = ModelCheckpoint(
                        client=client,
                        handle="default",
                        plugin_instance_id=tagger_instance.id,
                    )

tests/plugin/integration/test_e2e_trainable_tagger.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/steamship/plugin/outputs/model_checkpoint.py:51: in __init__
    super().__init__(client=client,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

&gt;   ???
E   pydantic.error_wrappers.ValidationError: 1 validation error for ModelCheckpoint
E   space
E     field required (type=value_error.missing)

pydantic/main.py:331: ValidationError</failure></testcase><testcase classname="tests.tests.plugin.unit.test_trainable_tagger" name="test_trainable_tagger" time="0.008"><failure message="pydantic.error_wrappers.ValidationError: 1 validation error for ModelCheckpoint&#10;space&#10;  field required (type=value_error.missing)">def test_trainable_tagger():
        client = get_steamship_client()
        assert client is not None
    
        plugin = TestTrainableTaggerPlugin(client=client)
        assert plugin.client is not None
    
        # STEP 1. Training Parameters
        # The first part of trainable is to produce trainable parameters. The end-user may offer inputs to this,
        # but ultimately it is the plugin itself which decides upon the final set of trainable parameters.
        tagger1 = plugin.get_training_parameters(
            PluginRequest(data=TrainingParameterPluginInput(), task_id="000", plugin_instance_id="000")
        )
        assert tagger1.data == TRAINING_PARAMETERS.to_dict()
        tagger2 = plugin.get_training_parameters_endpoint(
            **PluginRequest(
                data=TrainingParameterPluginInput(), task_id="000", plugin_instance_id="000"
            ).to_dict()
        )
        assert tagger2.data == TRAINING_PARAMETERS.to_dict()
        assert tagger2.data["trainingEpochs"] == TRAINING_PARAMETERS.training_epochs
    
        # STEP 2. Training
        # The first part of trainable is to produce your own trainable parameters.
&gt;       tagger1 = plugin.train(
            PluginRequest(
                data=TrainPluginInput(
                    plugin_instance="foo", training_params=TRAINING_PARAMETERS.training_params
                ),
                task_id="000",
                plugin_instance_id="000",
            )
        )

tests/plugin/unit/test_trainable_tagger.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
assets/plugins/taggers/plugin_trainable_tagger.py:168: in train
    archive_path_in_steamship = model.save_remote(
../src/steamship/plugin/trainable_model.py:161: in save_remote
    checkpoint = ModelCheckpoint(
../src/steamship/plugin/outputs/model_checkpoint.py:51: in __init__
    super().__init__(client=client,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

&gt;   ???
E   pydantic.error_wrappers.ValidationError: 1 validation error for ModelCheckpoint
E   space
E     field required (type=value_error.missing)

pydantic/main.py:331: ValidationError</failure></testcase><testcase classname="tests.tests.plugin.unit.trainable.test_model_checkpoints" name="test_model_checkpoint_save_load" time="2.123"><failure message="pydantic.error_wrappers.ValidationError: 1 validation error for ModelCheckpoint&#10;space&#10;  field required (type=value_error.missing)">def test_model_checkpoint_save_load():
        """A ModelCheckpoint captures the entire state of a model at any given time.
    
        On disk, it is a folder.
        - Models are expected to take this folder as their initialization input
        - Models are expected to persist whatever they need to persist to this folder during training.
    
        On Steamship, it is a zip archive stored in the associated PluginInstance's "Space Bucket"
        - Each ModelCheckpoint uploaded has a handle (like V1)
        - Every ModelCheckpoint uploaded can also become the new default
        """
        client = get_steamship_client()
        train_task_response = create_dummy_training_task(client)
        train_task_id = train_task_response.task.task_id
    
&gt;       checkpoint_1 = ModelCheckpoint(client=client, handle="epoch1", plugin_instance_id="0000")

tests/plugin/unit/trainable/test_model_checkpoints.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/steamship/plugin/outputs/model_checkpoint.py:51: in __init__
    super().__init__(client=client,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

&gt;   ???
E   pydantic.error_wrappers.ValidationError: 1 validation error for ModelCheckpoint
E   space
E     field required (type=value_error.missing)

pydantic/main.py:331: ValidationError</failure></testcase><testcase classname="tests.tests.plugin.unit.trainable.test_model_checkpoints" name="test_model_can_save_to_and_load_from_checkpoint" time="2.116"><failure message="pydantic.error_wrappers.ValidationError: 1 validation error for ModelCheckpoint&#10;space&#10;  field required (type=value_error.missing)">def test_model_can_save_to_and_load_from_checkpoint():
        """Elaboration of model_checkpoint_save_load in which include an example Model in the loop."""
    
        client = get_steamship_client()
        train_task_response = create_dummy_training_task(client)
        plugin_instance_id = "000"
    
        # TRAIN PHASE #1
        # ====================================
    
        # Create a new, empty checkpoint
    
        # Create a new model. Train it.
        model = TestTrainableTaggerModel()
        model.train(TrainPluginInput(plugin_instance="foo", training_params=TRAINING_PARAMETERS))
    
        # Create a checkpoint. Save the model to it. Upload it.
&gt;       model.save_remote(client=client, plugin_instance_id=plugin_instance_id, checkpoint_handle="V1")

tests/plugin/unit/trainable/test_model_checkpoints.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/steamship/plugin/trainable_model.py:161: in save_remote
    checkpoint = ModelCheckpoint(
../src/steamship/plugin/outputs/model_checkpoint.py:51: in __init__
    super().__init__(client=client,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

&gt;   ???
E   pydantic.error_wrappers.ValidationError: 1 validation error for ModelCheckpoint
E   space
E     field required (type=value_error.missing)

pydantic/main.py:331: ValidationError</failure></testcase><testcase classname="tests.utils.test_enums" name="test_enum_serialization_behavior" time="0.002"><failure message="AssertionError: assert 'TrainingPlatform.LAMBDA' == 'lambda'&#10;  - lambda&#10;  + TrainingPlatform.LAMBDA">def test_enum_serialization_behavior():
        assert json.dumps(TrainingPlatform.ECS) == '"ecs"'
    
        t1 = PluginInstance.from_dict({"training_platform": "ecs"})
        t2 = PluginInstance.from_dict({"training_platform": "lambda"})
    
        assert t1.training_platform == TrainingPlatform.ECS
        assert t2.training_platform == TrainingPlatform.LAMBDA
        assert t1.training_platform == "ecs"
        assert t2.training_platform == "lambda"
&gt;       assert str(t2.training_platform) == "lambda"
E       AssertionError: assert 'TrainingPlatform.LAMBDA' == 'lambda'
E         - lambda
E         + TrainingPlatform.LAMBDA

utils/test_enums.py:35: AssertionError</failure></testcase></testsuite></testsuites>